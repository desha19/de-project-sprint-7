{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession, DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window \n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(\"yarn\") \\\n",
    "                    .appName(\"Project_7_3\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для чтения файла \"/user/denis19/data/geo/cities/actual/geo.csv\" и переобразования\n",
    "def geo_transform(geo_path: str, sql) -> DataFrame:\n",
    "    geo_transform_df = (sql.read.option(\"header\", True)\n",
    "            .option(\"delimiter\", \";\")\n",
    "            .csv(geo_path)\n",
    "            .withColumn('lat_g', F.regexp_replace('lat', ',', '.').cast('float'))\n",
    "            .withColumn('lng_g', F.regexp_replace('lng', ',', '.').cast('float'))\n",
    "            .drop(\"lat\", \"lng\")\n",
    "            .persist()\n",
    "            )\n",
    "    return geo_transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcfb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "geo_transform_df = geo_transform(\"/user/denis19/data/geo/cities/actual/geo.csv\", spark)\n",
    "geo_transform_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a62560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция чтения \"/user/master/data/geo/events\" с переименованием стобцов lat на lat_e и lon на lon_e\n",
    "def events_transform(events_path: str, sql) -> DataFrame:\n",
    "    events_transform_df = (sql\n",
    "                  .read.parquet(f'{events_path}')\n",
    "                  .where('event_type = \"message\"')\n",
    "                  .select(\"event.message_id\", \"event.message_from\",\"event_type\", \"lat\", \"lon\", \"date\")\n",
    "                  .where('lat IS NOT NULL and lon IS NOT NULL')\n",
    "                  .withColumnRenamed(\"lat\", \"lat_e\")  # Переименование lat на lat_e\n",
    "                  .withColumnRenamed(\"lon\", \"lon_e\")  # Переименование lon на lon_e\n",
    "                  .persist()\n",
    "                  )\n",
    "    return events_transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "vents_transform_df = events_transform(\"/user/master/data/geo/events\", spark)\n",
    "vents_transform_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabde621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_with_geo(events_transform_df: DataFrame, geo_transform_df: DataFrame) -> DataFrame:\n",
    "    events_with_geo_df = (\n",
    "        # объединяем датафреймы \"events_transform_df\" и \"geo_transform_df\"\n",
    "        events_transform_df\n",
    "        .crossJoin(geo_transform_df)\n",
    "        # добавим столбец \"event_id\" с уникакльными значениями, используя функцию \"monotonically_increasing_id\"\n",
    "        .withColumn('event_id', F.monotonically_increasing_id())\n",
    "        # добавляем столбец \"distance\", который вычисляет расстояние между координатами событий и географическими координатами\n",
    "        .withColumn(\"distance\", F.lit(2) * F.lit(6371) * F.asin(\n",
    "        F.sqrt(\n",
    "            F.pow(F.sin((F.col(\"lat_e\") - F.col(\"lat_g\"))/F.lit(2)),2)\n",
    "            + F.cos(F.col(\"lat_g\"))*F.cos(F.col(\"lat_e\"))*\n",
    "            F.pow(F.sin((F.col(\"lon_e\") - F.col(\"lng_g\"))/F.lit(2)),2)\n",
    "        )))\n",
    "        # удаляем не нужные столбцы\n",
    "        .drop(\"lat_e\",\"lon_e\", \"lat_g\", \"lng_g\"))\n",
    "    # создадим окно, которое группирует строки по \"messenge_id\" и сортирует их по возростанию расстояния\n",
    "    window = Window().partitionBy('event_id').orderBy(F.col('distance').asc())\n",
    "    events_with_geo_df = (\n",
    "        events_with_geo_df\n",
    "        # добавим столбец \"row_number\", который присваивает каждой строке уникальный номер в пределах группы\n",
    "        .withColumn(\"row_number\", F.row_number().over(window))\n",
    "        # оставляем только строки с минимальным значением \"distance\" для каждого \"message_id\"\n",
    "        .filter(F.col('row_number')==1)\n",
    "        # удаление временных полей\n",
    "        .drop('row_number', 'distance')\n",
    "        # добавим столбец \"event_id\" с уникакльными значениями, используя функцию \"monotonically_increasing_id\"\n",
    "        #.withColumn('event_id', F.monotonically_increasing_id())\n",
    "        # выбираем и переименовываем необходимые столбцы\n",
    "        .selectExpr(\"message_id\", \"message_from as user_id\", \"event_id\", \"event_type\", \"id as zone_id\", \"city\", \"date\")\n",
    "        .persist()\n",
    "        )\n",
    "    return events_with_geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "events_with_geo_df = events_with_geo(events_transform_df, geo_transform_df)\n",
    "events_with_geo_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mart_zones(events_with_geo_df: DataFrame) -> DataFrame:\n",
    "    # группируем данные по \"user_id\" и сортируем их по дате по возрастанию\n",
    "    window = Window().partitionBy('user_id').orderBy(F.col('date').asc())\n",
    "    # группируем данные по \"zone_id\" и месяцу\n",
    "    w_month = Window.partitionBy(['zone_id', F.trunc(F.col(\"date\"), \"month\")])\n",
    "    # группируем данные по \"zone_id\" и неделе\n",
    "    w_week = Window.partitionBy(['zone_id', F.trunc(F.col(\"date\"), \"week\")])\n",
    "\n",
    "    registrations_df = (\n",
    "        events_with_geo_df\n",
    "        # добавляем столбец \"row_number\", который присваивает каждой строке уникальный номер в пределах группы \"user_id\"\n",
    "        .withColumn(\"row_number\", F.row_number().over(window))\n",
    "        # фильтруем строки, оставляя только первую строку для каждого \"user_id\"\n",
    "        .filter(F.col('row_number')==1)\n",
    "        .drop('row_number')\n",
    "        # добавляем столбцы \"month\" и \"week\", которые содержат усечённые значения даты до месяцы и недели\n",
    "        .withColumn(\"month\",F.trunc(F.col(\"date\"), \"month\"))\n",
    "        .withColumn(\"week\",F.trunc(F.col(\"date\"), \"week\"))\n",
    "        # добавляем столбцы \"week_user\" и \"month_user\", которые содержат количество уникальных пользователей за неделю и месяц\n",
    "        .withColumn(\"week_user\", F.count('user_id').over(w_week))\n",
    "        .withColumn(\"month_user\", F.count('user_id').over(w_month))\n",
    "        .selectExpr(\"month\",\"week\", \"week_user\", \"month_user\")\n",
    "        .distinct()\n",
    "        )\n",
    "\n",
    "    mart_zones_df = (events_with_geo_df\n",
    "          # добавляем столбцы \"month\" и \"week\" с усечёнными значениями даты\n",
    "          .withColumn(\"month\",F.trunc(F.col(\"date\"), \"month\"))\n",
    "          .withColumn(\"week\",F.trunc(F.col(\"date\"), \"week\"))\n",
    "          # добавляем столбцы с суммами за неделю и месяц\n",
    "          .withColumn(\"week_message\",F.sum(F.when(events_with_geo_df.event_type == \"message\",1).otherwise(0)).over(w_week))\n",
    "          .withColumn(\"week_reaction\",F.sum(F.when(events_with_geo_df.event_type == \"reaction\",1).otherwise(0)).over(w_week))\n",
    "          .withColumn(\"week_subscription\",F.sum(F.when(events_with_geo_df.event_type == \"subscription\",1).otherwise(0)).over(w_week))\n",
    "          .withColumn(\"month_message\",F.sum(F.when(events_with_geo_df.event_type == \"message\",1).otherwise(0)).over(w_month))\n",
    "          .withColumn(\"month_reaction\",F.sum(F.when(events_with_geo_df.event_type == \"reaction\",1).otherwise(0)).over(w_month))\n",
    "          .withColumn(\"month_subscription\",F.sum(F.when(events_with_geo_df.event_type == \"subscription\",1).otherwise(0)).over(w_month))\n",
    "          # объединяем данные с \"registrations_df\" по столбцам \"month\" и \"week\"\n",
    "          .join(registrations_df, [\"month\", \"week\"], \"fullouter\")\n",
    "          .select(\"month\", \"week\", \"zone_id\", \"week_message\", \"week_reaction\", \"week_subscription\", \"week_user\", \"month_message\", \"month_reaction\", \"month_subscription\", \"month_user\")\n",
    "          .distinct()\n",
    "          )\n",
    "    return mart_zones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303570ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "mart_zones_df = mart_zones(events_with_geo_df)\n",
    "mart_zones_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcee8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
